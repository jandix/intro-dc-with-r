---
title: "Session 6 - APIs"
subtitle: "An Introduction to Data Collection with R"
author: "Philipp Behrendt & Jan Dix"
date: "05. Juni 2018"
output: 
  ioslides_presentation:
    slide_level: 2
    logo: ../Assets/img/logo-uni.png
    widescreen: true
    css: ../Assets/css/style.css
---

```{r setup, include=FALSE, echo=F, error=F, warning=F, message=F}
knitr::opts_chunk$set(echo = TRUE)

# load required packages
library(tidyverse)
library(jsonlite)
library(xml2)
library(httr)
library(ggmap)
library(rtimes)
library(rtweet)
```

## Syllabus

Session 1 - R and RStudio

Session 2 - Data Typen und erste Befehle

Session 3 - Daten einlesen und speichern

Session 4 - Einfache Analyse (numerisch)

Session 5 - Visualisierung

`Session 6 - Application Programming Interfaces (APIs)`

Session 7 - Introduction to Text Mining

Session 8 & 9 - Web Scraping


## Agenda

1. Datenformate
2. Aufgaben
3. Was sind in APIs?
4. Aufgaben
5. Google Maps API
6. Aufgaben
7. New York Times API
8. Twitter API
9. Hausaufgaben


# Datenformate

## JSON (1)

```{json}
[
  {
    "name": "Batman",
    "age": 99
  },
  {
    "name": "Robin",
    "age": 101
  }
]
```

## JSON (2)

```{r, echo=FALSE}
json <- '[
  {
    "name": "Batman",
    "age": 99
  },
  {
    "name": "Robin",
    "age": 101
  }
]'
parsed_json <- fromJSON(json)
xml <- '<persons>
  <person>
    <name>Batman</name>
    <age>99</age>
  </person>
  <person>
    <name>Robin</name>
    <age>101</age>
  </person>
</persons>'
parsed_xml <- read_xml(xml)
parsed_persons <- xml_find_all(parsed_xml, "//persons")
parsed_text <- xml_text(parsed_persons)
```

```{r, eval=FALSE}
# parsing (lesen) json
library(jsonlite)
json <- readLines("batman.json")
parsed_json <- fromJSON(json)
```
```{r, echo=FALSE}
parsed_json
```

## XML (1)

```{xml}
<persons>
  <person>
    <name>Batman</name>
    <age>99</age>
  </person>
  <person>
    <name>Robin</name>
    <age>101</age>
  </person>
</persons>
```

## XML (2)

```{r, eval=FALSE}
# parsing (lesen) xml
library(xml2)
xml <- readLines("batman.xml")
parsed_xml <- read_xml(xml)
parsed_persons <- xml_find_all(parsed_xml, "//persons")
parsed_text <- xml_text(parsed_persons)
```
```{r, echo=FALSE}
parsed_text
```

## Aufgaben

```{r, echo=FALSE}
cars <- cars[1:5, ]
```

1. Erstelle eine JSON Datei von dem untenstehenden Datensatz.
2. Lese und parse die Datei [https://raw.githubusercontent.com/jandix/intro-dc-with-r/master/Data/Session_6/countries.json](https://raw.githubusercontent.com/jandix/intro-dc-with-r/master/Data/Session_6/countries.json).

```{r, echo=FALSE}
cars
```

# Was sind APIs?

## Was sind APIs? (1)

```{r, out.width = "65%",echo=FALSE, fig.align="center"}
knitr::include_graphics("../Assets/img/session6/api.png", dpi = 300)
```

## Was sind APIs? (2)

```{r, out.width = "100%",echo=FALSE}
knitr::include_graphics("../Assets/img/session6/url.png")
```

**BASE URL** (Stammurl): Wer bietet den Service an?

**ENDPOINT** (Endpunkt): Welchen Service möchtest du nutzten?

**PARAMETER** (Query): Auf welche Daten möchtest du zugreifen? Wie sollen die Daten gefiltert werden? 

## Was sind APIs? (3)

```{r}
library(httr)
url <- parse_url("http://maps.googleapis.com/maps/api/geocode/json")
url$query <- list(
  address = "Konstanz",
  sensor = "false"
)
url <- build_url(url)
```
```{r, echo=FALSE}
url
```

## Aufgaben

Unter [https://developers.google.com/maps/documentation/geocoding/intro](https://developers.google.com/maps/documentation/geocoding/intro) findest du die Dokumentation der Google Maps Geocoding API. Du kannst die Aufgaben entweder mit Hilfe des Browsers oder mit R lösen. **Tipp:** Im `httr` package gibt es die Funktionen `GET()` und `content()` mit deren Hilfe man Webseiten laden kann. 

1. Welche Koordinaten hat die Unversität Konstanz?
2. Zu welchem `administrative_area_level_2` gehört die Universität Harvard? 
3. Die API kann sowohl die Daten im `JSON` und `XML` Format ausgeben. Wie kann man das Format ändern? Welches Format ist besser?

# APIs in R

## ggmap (1)

```{r, message=F, eval=F}
# Paket laden
library(ggmap)
# Koordinaten für Konstanz
geocode("Konstanz")
```

```{r, echo=F, message=F}
coord <- geocode("Konstanz")
coord
```


```{r, eval=F, message=F}
# 
revgeocode(location = as.numeric(coord[1,]),
           output = "more")
```

## ggmap (2)

## Aufgaben

1. Nutze die Koordinaten aus dem `gtdb` Datensatz, um den Datensatz mit Stadt, Bundesland/State und Land zu erweitern. Nutze dazu das `ggmap`-Package. 

## rtimes (1)

- Key beantragen: [https://developer.nytimes.com/signup](https://developer.nytimes.com/signup)
- Key speichern unter `.Renviron`

```{bash, eval=F}
NYTIMES_AS_KEY=***
```

## rtimes (2)

```{r, message=F, eval=F}
# Paket laden
library(rtimes)
#
as_search("")

```

## Hausaufgaben

1. Erstelle ein Sample basierend auf einem Land (z.B.: Swasiland) und einem Zeitraum (max. 1 Jahr). 
2. Überlege dir eine Strategie, um für jedes Ereignis in deinem Sample, Zeitungsartikel in der New York Times API zu finden. Kombiniere dazu geschickt **Zeit**, **attack_type** und Ort.
3. Speicher alle Metadaten zu den Zeitungsartikeln in einem neuen `data.frame` mit dem Namen `nyt_articles`.




